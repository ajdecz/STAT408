---
title: "Homework 4"
format: 
  html:
    self-contained: true
    embed-resources: true
editor: visual
execute: 
  echo: true
  include: true
---

Please upload an html/pdf to Sakai by Wednesday, October 1, at 6 pm.

1.  Consider the attached rds files:

-   X1.rds, containing the model matrix of a reduced model with a single explanatory variable ($X_1$)
-   X2.rds, containing the model matrix of a full model with two explanatory variables, one numeric ($X_1$) and one categorical ($X_2$)
-   y.rds, containing the observations of a response variable ($y$)

**Note**: you can use the function readRDS in R to upload these types of data files (the syntax is otherwise the same)

a.  Using linear algebra, perform a formal hypothesis test to determine if the variable $X_1$ and $y$ have a statistically significant linear relationship.

    Reduced Model: $\hat{Y} = \beta_0$

    Full Model: $\hat{Y} = \beta_0 + \beta_1X$

    $H_0: \beta_1 = 0, H_a: \beta_1 \neq 0$

    $t = 3.66, p = 0.0015$

    Therefore we can reject the null hypothesis and say that $\beta_1 \neq 0$ and the variable $X_1$ and $y$ have a statistically significant linear relationship.

```{r}
X1 <- readRDS("Data/X1.rds")
X2 <- readRDS("Data/X2.rds")
y  <- readRDS("Data/y.rds")

X1 <- as.matrix(X1)
X2 <- as.matrix(X2)
y  <- as.matrix(y)

n1  <- nrow(X1)
p1 <- ncol(X1)

XtX_1    <- t(X1) %*% X1               
XtX_1inv <- solve(XtX_1)               
P1       <- X1 %*% XtX_1inv %*% t(X1)  

yhat1 <- P1 %*% y                      
resid1 <- y - yhat1                    

SSE1 <- (t(resid1) %*% resid1)

sigma2_hat_1 <- SSE1 / (n1 - p1)

beta_hat_1 <- XtX_1inv %*% (t(X1) %*% y)
Var_beta_1 <- as.numeric(sigma2_hat_1) * XtX_1inv

t_stat <- (beta_hat_1[2,1] / sqrt(Var_beta_1[2,2]))
df     <- n1 - p1
p_val  <- 2 * (1 - pt(abs(t_stat), df))

t_stat
p_val
```

b.  Using linear algebra, find the proportion of variation in $y$ that is explained by a linear model with $X_1$ and $X_2$.

    $r^2 = 0.1911$ , meaning 19.11% of the proportion of variation in y is explained by a linear model with both $X1$ and $X2$

```{r}
BX2 <- solve(t(X2) %*% X2) %*% t(X2) %*% y
ybar <- mean(y)
SSEX2 <- t(y - X2 %*% BX2) %*% (y - X2 %*% BX2)
SSTX2 <- sum((y - ybar)^2)
SSMX2 <- SSTX2 - SSEX2
R2X2 <- SSMX2 / SSTX2

R2X2
```

c.  Assume that the linear model in (a) is statistically significant. Using linear algebra, perform a formal hypothesis test to determine if adding the variable $X_2$ to the linear model in (a) is statistically significant.

    Reduced Model: $\hat{Y} = \beta_0 + \beta_1 X1$

    Full Model: $\hat{Y} = \beta_0 + \beta_1 X1 + \beta_2 X2$

    $H_0: \beta_2 = 0, H_a: \beta_2 \neq 0$

    $F = 5.54, p = 0.0053$ , therefore we reject the null hypothesis and can conclude that adding $X2$ as an explanatory variable to a linear model that already includes $y$ as a response variable and $X1$ as an explanatory variable.

```{r}
n  <- nrow(X1)
pR <- ncol(X1)
pF <- ncol(X2)
q  <- pF - pR
I  <- diag(n)

PR <- X1 %*% solve(t(X1) %*% X1) %*% t(X1)
PF <- X2 %*% solve(t(X2) %*% X2) %*% t(X2)

SSE_R <- as.numeric(t(y) %*% (I - PR) %*% y)
SSE_F <- as.numeric(t(y) %*% (I - PF) %*% y)

num <- (SSE_R - SSE_F) / q
den <- SSE_F / (n - pF)
f   <- num / den
p <- 1 - pf(f, q, n - pF)

f
p


#check to make sure 
modred <- lm(y ~ X1)
modfull <- lm(y ~ X2)
anova(modred, modfull)
# yup we good 
```

d.  For the model that you choose in (b), determine if there are any influential observations.

    From the studentized values of the linear relationship of y and X1 and X2, we can determine that observations 11 and 73 are influential observations.

```{r}

# From class convo it is clear you wanted linear but I did rstud() method first 

# initial observation
plot(modfull,1) #modfull is y ~ XZ (above)


# obs 11 is an influential observation, 73
rstud <- rstudent(modfull)
id1 <- which.max(abs(rstud))
n <- nrow(X2)
k <- 4
alpha <- 0.01 
crit <- qt(1-alpha/2,n-k-1)
(abs(rstud)[id1] > crit)

# observation 73 is our next influential observation
modfull2 <- lm(y[-11,] ~ X2[-11, -1])
rstud2 <- rstudent(modfull2)
id2 <- which.max(abs(rstud2))
abs(rstud2)[id2] > crit

# next one 42 is not an influential observation
infl_obs <- c(11,73)
modfull3 <- lm(y[-infl_obs,] ~ X2[-infl_obs, -1])
rstud3 <- rstudent(modfull3)
id3 <- which.max(abs(rstud3))
abs(rstud3)[id3] > crit


# LINEAR

# first test, 11 is influential
hat_mat <- X2 %*% solve(t(X2) %*% X2) %*% t(X2)
yhatx2 <- X2 %*% BX2
errorest <- y - yhatx2
lev <- diag(hat_mat)
MSEX2 <- SSEX2 / (nrow(X2) - k)
stud_resid <- errorest / sqrt(as.numeric(MSEX2)) * sqrt(1 - lev)
id4 <- which.max(abs(stud_resid)) 
id4
abs(stud_resid)[id4] > crit
# 11 is true 

#second test, 73 is influential 
X2_rm11 <- X2[-11,]
hat_mat <- X2_rm11 %*% solve(t(X2_rm11) %*% X2_rm11) %*% t(X2_rm11)
yhatx2 <- X2_rm11 %*% BX2
errorest <- y[-11,] - yhatx2
lev <- diag(hat_mat)
MSEX2 <- SSEX2 / (nrow(X2_rm11) - k)
stud_resid <- errorest / sqrt(as.numeric(MSEX2)) * sqrt(1 - lev)
id5 <- which.max(abs(stud_resid)) 
id5
abs(stud_resid)[id5] > crit

#third test 
inf <- c(11,73)
X2_rm_inf <- X2[-inf,]
hat_mat <- X2_rm_inf %*% solve(t(X2_rm_inf) %*% X2_rm_inf) %*% t(X2_rm_inf)
yhatx2 <- X2_rm_inf %*% BX2
errorest <- y[-inf] - yhatx2
lev <- diag(hat_mat)
MSEX2 <- SSEX2 / (nrow(X2_rm_inf) - k)
stud_resid <- errorest / sqrt(as.numeric(MSEX2)) * sqrt(1 - lev)
id6 <- which.max(abs(stud_resid)) 
id6
abs(stud_resid)[id6] > crit

```
